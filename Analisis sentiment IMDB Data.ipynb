{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9ffbe9-21cb-4ed9-98ae-3d3e547684b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae7fc05-e478-4f8f-9d8a-443bb7feaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function (IMDB - English)\n",
    "def preprocess_text_english(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetical characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785e1007-ece1-45a0-b233-6cb41fd0b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Contoh dataset IMDB dan ulasan produk Indonesia\n",
    "imdb_data = pd.read_csv('IMDB_Dataset.csv')\n",
    "\n",
    "# Preprocessing IMDB\n",
    "imdb_data['cleaned_review'] = imdb_data['review'].apply(preprocess_text_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e1d99e1-80bb-4138-aa9b-15b1a24fdf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Cleaned Reviews:\n",
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one review mention watch oz episod youll hook ...  \n",
      "1  wonder littl product br br film techniqu unass...  \n",
      "2  thought wonder way spend time hot summer weeke...  \n",
      "3  basic there famili littl boy jake think there ...  \n",
      "4  petter mattei love time money visual stun film...  \n"
     ]
    }
   ],
   "source": [
    "# Menampilkan beberapa baris pertama dari cleaned_review pada dataset IMDB\n",
    "print(\"IMDB Cleaned Reviews:\")\n",
    "print(imdb_data[['review', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09cec534-4d1a-4108-bd80-8c42228e32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorization (IMDB):\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Shape of IMDB TF-IDF matrix: (50000, 137558)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# IMDB dataset vectorization\n",
    "X = tfidf_vectorizer.fit_transform(imdb_data['cleaned_review'])\n",
    "y = imdb_data['sentiment']  # Assume sentiment is labeled as 'positive' or 'negative'\n",
    "\n",
    "# Menampilkan hasil vektorisasi dari dataset IMDB\n",
    "print(\"TF-IDF Vectorization (IMDB):\")\n",
    "print(X[:100].toarray())  # Mengubah sparse matrix menjadi array agar bisa dilihat hasilnya\n",
    "print(\"Shape of IMDB TF-IDF matrix:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f0489b3-e8fc-491f-9b9a-f20a533cd8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (37500, 137558), Test shape: (12500, 137558)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Memisahkan fitur dan label\n",
    "y = imdb_data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f'Train shape: {X_train.shape}, Test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a256fe9b-e349-4ba7-aef8-66b40c246b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Logistic Regression: 0.88968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      6157\n",
      "    positive       0.88      0.90      0.89      6343\n",
      "\n",
      "    accuracy                           0.89     12500\n",
      "   macro avg       0.89      0.89      0.89     12500\n",
      "weighted avg       0.89      0.89      0.89     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logreg_model = LogisticRegression()  # Inisialisasi model Logistic Regression\n",
    "logreg_model.fit(X_train, y_train)  # Latih model dengan data pelatihan\n",
    "\n",
    "y_pred_logreg = logreg_model.predict(X_test)  # Prediksi data uji\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(\"Akurasi Logistic Regression:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1711eb57-574d-45e4-b84b-8ee7cef2cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Naive Bayes : 0.86096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86      6157\n",
      "    positive       0.88      0.84      0.86      6343\n",
      "\n",
      "    accuracy                           0.86     12500\n",
      "   macro avg       0.86      0.86      0.86     12500\n",
      "weighted avg       0.86      0.86      0.86     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb_model = MultinomialNB()  # Inisialisasi model Naive Bayes\n",
    "nb_model.fit(X_train, y_train)  # Latih model dengan data pelatihan\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)  # Prediksi data uji\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(\"Akurasi Naive Bayes :\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc49089-537b-41e0-a9f7-bcc3682db7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Decision Tree: 0.72032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.72      0.72      6157\n",
      "    positive       0.73      0.72      0.72      6343\n",
      "\n",
      "    accuracy                           0.72     12500\n",
      "   macro avg       0.72      0.72      0.72     12500\n",
      "weighted avg       0.72      0.72      0.72     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dt_model = DecisionTreeClassifier()  # Inisialisasi model Decision Tree\n",
    "dt_model.fit(X_train, y_train)  # Latih model dengan data pelatihan\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)  # Prediksi data uji\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(\"Akurasi Decision Tree:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bde945d7-f64b-4e1f-b354-6a2529d28a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Random Forest: 0.85056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85      6157\n",
      "    positive       0.86      0.84      0.85      6343\n",
      "\n",
      "    accuracy                           0.85     12500\n",
      "   macro avg       0.85      0.85      0.85     12500\n",
      "weighted avg       0.85      0.85      0.85     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf_model = RandomForestClassifier()  # Inisialisasi model Random Forest\n",
    "rf_model.fit(X_train, y_train)  # Latih model dengan data pelatihan\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)  # Prediksi data uji\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(\"Akurasi Random Forest:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5176e4b-b024-4e4e-ae24-2adb2164c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svm_model = SVC()  # Inisialisasi model SVM\n",
    "svm_model.fit(X_train, y_train)  # Latih model dengan data pelatihan\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)  # Prediksi data uji\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(\"Akurasi SVM:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fd828-247d-47a2-bfaf-3c026cca9f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
